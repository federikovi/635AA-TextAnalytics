{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"k4WO3a6GNNth","colab_type":"text"},"cell_type":"markdown","source":["# LSTM"]},{"metadata":{"id":"UyrItfm_NNti","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5b7ac5ca-fcfc-4223-c4e5-84a92cdaeefe","executionInfo":{"status":"ok","timestamp":1547383188222,"user_tz":-60,"elapsed":1934,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, CuDNNLSTM\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","from time import time"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"lqm1_YrCNPm2","colab_type":"code","colab":{}},"cell_type":"code","source":["# Code to read csv file into Colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EcDnp5HWNVAY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"82ad98c3-0dee-42a0-e5b7-3227b41e7127","executionInfo":{"status":"ok","timestamp":1547383218200,"user_tz":-60,"elapsed":22595,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["link_train = 'https://drive.google.com/open?id=1wocSG9KQQRB9VvfFceYoWB8gAH0MoFAV'\n","fluff, id = link_train.split('=')\n","print (id) # Verify that you have everything after '='"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1wocSG9KQQRB9VvfFceYoWB8gAH0MoFAV\n"],"name":"stdout"}]},{"metadata":{"id":"OZoWY6aJNq7_","colab_type":"code","colab":{}},"cell_type":"code","source":["downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('dataset_05.csv')  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"DDT3VPCCNxK2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dd57e330-f4b8-40f2-dc67-5a605dc8e37f","executionInfo":{"status":"ok","timestamp":1547383219766,"user_tz":-60,"elapsed":21565,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["link_test = 'https://drive.google.com/open?id=1bOj5vMjlTnMTEBNImASqwXuHiJ0WB2ab'\n","fluff, id1 = link_test.split('=')\n","print (id1) # Verify that you have everything after '='"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1bOj5vMjlTnMTEBNImASqwXuHiJ0WB2ab\n"],"name":"stdout"}]},{"metadata":{"id":"8K2PHqDQOFVW","colab_type":"code","colab":{}},"cell_type":"code","source":["downloaded1 = drive.CreateFile({'id':id1}) \n","downloaded1.GetContentFile('finaltest.csv') "],"execution_count":0,"outputs":[]},{"metadata":{"id":"KnxKnTmgNNtl","colab_type":"code","colab":{}},"cell_type":"code","source":["columns = ['','text_final','polarity','VADER_score','VADER_binary']\n","\n","train = pd.read_csv('dataset_05.csv',\n","                     header = 0,\n","                     names = columns,\n","                     usecols = [1,2],\n","                     encoding ='ISO-8859-1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5EropP79NNto","colab_type":"code","colab":{}},"cell_type":"code","source":["columns_test = ['','text_no_tag','polarity','length']\n","test = pd.read_csv('finaltest.csv',\n","                     usecols = [1,2],\n","                     header = 0,\n","                     names = columns_test,\n","                     encoding ='ISO-8859-1')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1zjerMGNNtq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d4c91cf0-91f6-4f74-e043-3b89391ba4fd","executionInfo":{"status":"ok","timestamp":1547383221615,"user_tz":-60,"elapsed":16992,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["len_train = len(train)\n","print(\"len training: \" , len_train)\n","len_test = len(test)\n","print(\"len test: \" , len_test)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["len training:  602766\n","len test:  359\n"],"name":"stdout"}]},{"metadata":{"id":"iKyPP1syNNtu","colab_type":"text"},"cell_type":"markdown","source":["### test polarity 4 ->1"]},{"metadata":{"id":"aVyfbq7ENNtv","colab_type":"code","colab":{}},"cell_type":"code","source":["test['polarity'].replace(to_replace=[4],value=1,inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LZSCj0UmNNtx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"b3b5f014-d714-4f84-f7e6-7c6e09b81ab3","executionInfo":{"status":"ok","timestamp":1547383228920,"user_tz":-60,"elapsed":958,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["train.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_final</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>is upset that he can not update his facebook b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@USER no , it ' s not behaving at all . i am m...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@USER hey long time no see ! yes .  rains a bi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER i could not bear to watch it . and i tho...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hollis ' death scene will hurt me severely to ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          text_final  polarity\n","0  is upset that he can not update his facebook b...         0\n","1  @USER no , it ' s not behaving at all . i am m...         0\n","2  @USER hey long time no see ! yes .  rains a bi...         0\n","3  @USER i could not bear to watch it . and i tho...         0\n","4  hollis ' death scene will hurt me severely to ...         0"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"sd2sGBfINNt0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"e5eecc55-697e-4f09-ae1f-21037208d875","executionInfo":{"status":"ok","timestamp":1547383230311,"user_tz":-60,"elapsed":608,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@USER i love  my kindle2 . not that the  is co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>reading my kindle2 .  love it .  lee childs is...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ok , first assesment of the kindle 2 .  it fuc...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER you will love your kindle2 . i have had ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@USER fair enough . but i have the kindle2 and...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         text_no_tag  polarity\n","0  @USER i love  my kindle2 . not that the  is co...         1\n","1  reading my kindle2 .  love it .  lee childs is...         1\n","2  ok , first assesment of the kindle 2 .  it fuc...         1\n","3  @USER you will love your kindle2 . i have had ...         1\n","4  @USER fair enough . but i have the kindle2 and...         1"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"lfMrqCIZNNt2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"bdec9386-dcf8-4440-e338-47fc9d0cd0d1","executionInfo":{"status":"ok","timestamp":1547383232058,"user_tz":-60,"elapsed":780,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["train.tail()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_final</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>602761</th>\n","      <td>woo  ! xbox is back</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>602762</th>\n","      <td>@USER yeah , that does work better than just w...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>602763</th>\n","      <td>just woke up . having no school is the best fe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>602764</th>\n","      <td>happy 3 8 th birthday to my boo of all  time !...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>602765</th>\n","      <td>happy charity tuesday @USER @USER @USER</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               text_final  polarity\n","602761                                woo  ! xbox is back         1\n","602762  @USER yeah , that does work better than just w...         1\n","602763  just woke up . having no school is the best fe...         1\n","602764  happy 3 8 th birthday to my boo of all  time !...         1\n","602765            happy charity tuesday @USER @USER @USER         1"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"g949uC5lNNt5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"28a1e84b-a6fb-4575-c8d4-fd2868dbf074","executionInfo":{"status":"ok","timestamp":1547383233689,"user_tz":-60,"elapsed":727,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test.tail()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>354</th>\n","      <td>after using latex a lot , any other typeset ma...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>355</th>\n","      <td>on that note , i hate word . i hate pages . i ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>ah  .  back in a *real* text editing environme...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>trouble in iran , i see . hmm . iran . iran so...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>reading the tweets coming out of iran .  the w...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           text_no_tag  polarity\n","354  after using latex a lot , any other typeset ma...         1\n","355  on that note , i hate word . i hate pages . i ...         0\n","356  ah  .  back in a *real* text editing environme...         1\n","357  trouble in iran , i see . hmm . iran . iran so...         0\n","358  reading the tweets coming out of iran .  the w...         0"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"8mXWRsZzNNt8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"6eebb589-bb79-4edb-dc27-bb9e13b4a44b","executionInfo":{"status":"ok","timestamp":1547383236330,"user_tz":-60,"elapsed":1010,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["print(\"n positive tweets:   \", len(train[train['polarity'] == 0]))\n","print(\"n negative tweets:   \", len(train[train['polarity'] == 1]))\n","print(\"size positive tweets:   \", train[train['polarity'] == 0].size)\n","print(\"size negative tweets:   \", train[train['polarity'] == 1].size)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["n positive tweets:    253678\n","n negative tweets:    349088\n","size positive tweets:    507356\n","size negative tweets:    698176\n"],"name":"stdout"}]},{"metadata":{"id":"cK2nxBXLNNt_","colab_type":"text"},"cell_type":"markdown","source":["### modules explaination\n","\n","```from keras.preprocessing.text import Tokenizer```\n","\n","```num_words```: the maximum number of words to keep, based on word frequency. Only the most common num_words words will be kept.\n","\n","---\n","\n","- ```fit_on_texts(texts):``` <br>\n","__Arguments__: <br>\n","__texts__: list of texts to train on.\n","    \n","- ```texts_to_sequences(texts)``` <br>\n","__Arguments__:<br>\n","    __texts__: list of texts to turn to sequences.<br>\n","__Return__: list of sequences (one per text input).\n","\n","---\n","\n","```from keras.preprocessing.sequence import pad_sequences```\n","\n","Pads sequences to the same length.<br>\n","\n","This function transforms a list of num_samples sequences (lists of integers) into a 2D Numpy array of shape (num_samples, num_timesteps). num_timesteps is either the maxlen argument if provided, or the length of the longest sequence otherwise.<br>\n","\n","Sequences that are shorter than num_timesteps are padded with value at the end.<br>\n","\n","Sequences longer than num_timesteps are truncated so that they fit the desired length. The position where padding or truncation happens is determined by the arguments padding and truncating, respectively.<br>\n","\n","Pre-padding is the default.\n","\n","```keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)```\n","\n","__Arguments__\n","\n","- __sequences__: List of lists, where each element is a sequence.\n","- __maxlen__: Int, maximum length of all sequences.\n","- __dtype__: Type of the output sequences. To pad sequences with variable length strings, you can use object.\n","- __padding__: String, 'pre' or 'post': pad either before or after each sequence.\n","- __truncating__: String, 'pre' or 'post': remove values from sequences larger than  maxlen, either at the beginning or at the end of the sequences.\n","- __value__: Float or String, padding value.\n"]},{"metadata":{"id":"zrm2dbtpNNt_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"ea9b52a1-b310-4fd3-c68f-fec801fa8415","executionInfo":{"status":"ok","timestamp":1547383273529,"user_tz":-60,"elapsed":33677,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["%%time\n","max_features = 2000\n","tokenizer = Tokenizer(num_words=max_features, split=' ')\n","tokenizer.fit_on_texts(train['text_final'].values)\n","\n","X = tokenizer.texts_to_sequences(train['text_final'].values)\n","X = pad_sequences(X)\n","print(X.shape)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(602766, 61)\n","CPU times: user 32.7 s, sys: 192 ms, total: 32.8 s\n","Wall time: 32.9 s\n"],"name":"stdout"}]},{"metadata":{"id":"DMFpInEwNNuC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"287b95dc-07bb-4d0a-ca78-55ac164fbaf1","executionInfo":{"status":"ok","timestamp":1547383273529,"user_tz":-60,"elapsed":15140,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["print(X.shape[1])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["61\n"],"name":"stdout"}]},{"metadata":{"id":"k2ymvRzWNNuF","colab_type":"text"},"cell_type":"markdown","source":["### Keras Sequential model\n","\n","- ```model = Sequential()```<br>\n","__[READ ME: SEQUENTIAL MODEL EXPLAINATION](https://keras.io/getting-started/sequential-model-guide/)__\n","\n","\n","- ```keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)``` <br><br>\n","__Arguments__<br>\n","    - __input_dim__: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n","    - __output_dim__: int >= 0. Dimension of the dense embedding.\n","    - __embeddings_initializer__: Initializer for the embeddings matrix (see initializers).\n","    - __embeddings_regularizer__: Regularizer function applied to the embeddings matrix (see regularizer).\n","    - __embeddings_constraint__: Constraint function applied to the embeddings matrix (see constraints).\n","    - __mask_zero__: Whether or not the input value 0 is a special \"padding\" value that should be masked out. This is useful when using recurrent layers which may take variable length input. If this is True then all subsequent layers in the - model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1).\n","    - __input_length__: Length of input sequences, when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).<br><br>\n","    \n","- ```SpatialDropout1D(rate)``` <br>\n","Spatial 1D version of Dropout. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.<br>\n","This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.<br><br>\n","\n","- ```keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)```<br>\n","Long Short-Term Memory layer - Hochreiter 1997.<br><br>\n","__Arguments__<br><br>\n","    - __units__: Positive integer, dimensionality of the output space.\n","    - __activation__: Activation function to use (see activations). Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\n","    - __recurrent_activation__: Activation function to use for the recurrent step (see activations). Default: hard sigmoid (hard_sigmoid). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\n","use_bias: Boolean, whether the layer uses a bias vector.\n","    - __kernel_initializer__: Initializer for the kernel weights matrix, used for the linear transformation of the inputs. (see initializers).\n","    - __recurrent_initializer__: Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent state. (see initializers).\n","    - __bias_initializer__: Initializer for the bias vector (see initializers).\n","    - __unit_forget_bias__: Boolean. If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force bias_initializer=\"zeros\". This is recommended in Jozefowicz et al. (2015).\n","    - __kernel_regularizer__: Regularizer function applied to the kernel weights matrix (see regularizer).\n","    - __recurrent_regularizer__: Regularizer function applied to the recurrent_kernel weights matrix (see regularizer).\n","    - __bias_regularizer__: Regularizer function applied to the bias vector (see regularizer).\n","    - __activity_regularizer__: Regularizer function applied to the output of the layer (its \"activation\"). (see regularizer).\n","    - __kernel_constraint__: Constraint function applied to the kernel weights matrix (see constraints).\n","    - __recurrent_constraint__: Constraint function applied to the recurrent_kernel weights matrix (see constraints).\n","    - __bias_constraint__: Constraint function applied to the bias vector (see constraints).\n","    - __dropout__: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs.\n","    - __recurrent_dropout__: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n","    - __implementation__: Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications.\n","return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n","    - __return_state__: Boolean. Whether to return the last state in addition to the output.\n","    - __go_backwards__: Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.\n","    - __stateful__: Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n","    - __unroll__: Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.<br><br>\n","    \n","- ```keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)```<br>\n","Just your regular densely-connected NN layer.<br>\n","Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).<br>\n","Note: if the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with kernel.<br>\n","__Arguments__\n","\n","   - __units__: Positive integer, dimensionality of the output space.\n","   - __activation__: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n","   - __use_bias__: Boolean, whether the layer uses a bias vector.\n","   - __kernel_initializer__: Initializer for the kernel weights matrix (see initializers).\n","   - __bias_initializer__: Initializer for the bias vector (see initializers).\n","   - __kernel_regularizer__: Regularizer function applied to the kernel weights matrix (see regularizer).\n","   - __bias_regularizer____: Regularizer function applied to the bias vector (see regularizer).\n","   - __activity_regularizer__: Regularizer function applied to the output of the layer (its \"activation\"). (see regularizer).\n","   - __kernel_constraint__: Constraint function applied to the kernel weights matrix (see constraints).\n","   - __bias_constraint__: Constraint function applied to the bias vector (see constraints)."]},{"metadata":{"id":"Zm-uqcVTNNuG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"33df26d1-c904-40a5-afb7-c3fc2ec3e10e","executionInfo":{"status":"ok","timestamp":1547383288370,"user_tz":-60,"elapsed":8368,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["from keras.layers import Bidirectional\n","\n","embed_dim = 128\n","lstm_out = 10\n","\n","model = Sequential()\n","model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n","model.add(SpatialDropout1D(0.4))\n","model.add(Bidirectional(CuDNNLSTM(lstm_out)))\n","model.add(Dense(2, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"],"execution_count":18,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 61, 128)           256000    \n","_________________________________________________________________\n","spatial_dropout1d_1 (Spatial (None, 61, 128)           0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 20)                11200     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 42        \n","=================================================================\n","Total params: 267,242\n","Trainable params: 267,242\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"GWbyboykNNuJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"d421b2f1-ca16-4a03-9ab7-66c0c6d24060","executionInfo":{"status":"ok","timestamp":1547383292779,"user_tz":-60,"elapsed":1014,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["%%time\n","Y = pd.get_dummies(train['polarity']).values\n","X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n","print(X_train.shape,Y_train.shape)\n","print(X_test.shape,Y_test.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["(403853, 61) (403853, 2)\n","(198913, 61) (198913, 2)\n","CPU times: user 125 ms, sys: 55 ms, total: 180 ms\n","Wall time: 181 ms\n"],"name":"stdout"}]},{"metadata":{"id":"E_l6W3pVNNuM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"526dc394-d32c-4e81-e746-dea0a0bb2be2","executionInfo":{"status":"ok","timestamp":1547383295847,"user_tz":-60,"elapsed":1059,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test.head()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@USER i love  my kindle2 . not that the  is co...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>reading my kindle2 .  love it .  lee childs is...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ok , first assesment of the kindle 2 .  it fuc...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER you will love your kindle2 . i have had ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@USER fair enough . but i have the kindle2 and...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         text_no_tag  polarity\n","0  @USER i love  my kindle2 . not that the  is co...         1\n","1  reading my kindle2 .  love it .  lee childs is...         1\n","2  ok , first assesment of the kindle 2 .  it fuc...         1\n","3  @USER you will love your kindle2 . i have had ...         1\n","4  @USER fair enough . but i have the kindle2 and...         1"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"Ox-Q0ewjNNuQ","colab_type":"text"},"cell_type":"markdown","source":["```fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)```<br>\n","Trains the model for a given number of epochs (iterations on a dataset).\n","\n","__Arguments__\n","\n","- __x__: Numpy array of training data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs). If input layers in the model are named, you can also pass a dictionary mapping input names to Numpy arrays.  x can be None (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).\n","- __y__: Numpy array of target (label) data (if the model has a single output), or list of Numpy arrays (if the model has multiple outputs). If output layers in the model are named, you can also pass a dictionary mapping output names to Numpy arrays.  y can be None (default) if feeding from framework-native tensors (e.g. TensorFlow data tensors).\n","- __batch_size__: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n","- __epochs__: Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Note that in conjunction with initial_epoch,  epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n","- __verbose__: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n","- __callbacks__: List of keras.callbacks.Callback instances. List of callbacks to apply during training. See callbacks.\n","- __validation_split__: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n","- __validation_data__: tuple (x_val, y_val) or tuple  (x_val, y_val, val_sample_weights) on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.  validation_data will override validation_split.\n","- __shuffle__: Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None.\n","- __class_weight__: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n","- __sample_weight__: Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape  (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n","- __initial_epoch__: Integer. Epoch at which to start training (useful for resuming a previous training run).\n","- __steps_per_epoch__: Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined.\n","- __validation_steps__: Only relevant if steps_per_epoch is specified. Total number of steps (batches of samples) to validate before stopping.\n"]},{"metadata":{"id":"jZshu22XNNuR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1527},"outputId":"eb1400d1-f530-4d44-a8fe-71a7d936cc22","executionInfo":{"status":"error","timestamp":1547385666557,"user_tz":-60,"elapsed":2365129,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","batch_size = 32\n","checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True)\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0.001, patience=30, verbose=1\n",")\n","\n","callbacks_list = [checkpoint, early_stopping]\n","model.fit(X_train, Y_train, validation_split=0.2, epochs=200, batch_size=batch_size, verbose=2, callbacks=callbacks_list)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train on 323082 samples, validate on 80771 samples\n","Epoch 1/200\n"," - 239s - loss: 0.3997 - acc: 0.8188 - val_loss: 0.3765 - val_acc: 0.8312\n","\n","Epoch 00001: val_loss improved from inf to 0.37647, saving model to model.h5\n","Epoch 2/200\n"," - 235s - loss: 0.3699 - acc: 0.8352 - val_loss: 0.3666 - val_acc: 0.8370\n","\n","Epoch 00002: val_loss improved from 0.37647 to 0.36665, saving model to model.h5\n","Epoch 3/200\n"," - 234s - loss: 0.3594 - acc: 0.8405 - val_loss: 0.3625 - val_acc: 0.8411\n","\n","Epoch 00003: val_loss improved from 0.36665 to 0.36255, saving model to model.h5\n","Epoch 4/200\n"," - 235s - loss: 0.3527 - acc: 0.8439 - val_loss: 0.3623 - val_acc: 0.8406\n","\n","Epoch 00004: val_loss improved from 0.36255 to 0.36226, saving model to model.h5\n","Epoch 5/200\n"," - 235s - loss: 0.3474 - acc: 0.8470 - val_loss: 0.3604 - val_acc: 0.8415\n","\n","Epoch 00005: val_loss improved from 0.36226 to 0.36037, saving model to model.h5\n","Epoch 6/200\n"," - 234s - loss: 0.3433 - acc: 0.8491 - val_loss: 0.3638 - val_acc: 0.8413\n","\n","Epoch 00006: val_loss did not improve from 0.36037\n","Epoch 7/200\n"," - 236s - loss: 0.3402 - acc: 0.8501 - val_loss: 0.3605 - val_acc: 0.8424\n","\n","Epoch 00007: val_loss did not improve from 0.36037\n","Epoch 8/200\n"," - 236s - loss: 0.3378 - acc: 0.8520 - val_loss: 0.3619 - val_acc: 0.8421\n","\n","Epoch 00008: val_loss did not improve from 0.36037\n","Epoch 9/200\n"," - 236s - loss: 0.3356 - acc: 0.8528 - val_loss: 0.3625 - val_acc: 0.8425\n","\n","Epoch 00009: val_loss did not improve from 0.36037\n","Epoch 10/200\n"," - 236s - loss: 0.3337 - acc: 0.8542 - val_loss: 0.3632 - val_acc: 0.8410\n","\n","Epoch 00010: val_loss did not improve from 0.36037\n","Epoch 11/200\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-dd5fcb5a0ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"IDrITIgTNNuV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fd722e8e-79cd-4b74-ad68-82ae0f541906","executionInfo":{"status":"ok","timestamp":1547385756530,"user_tz":-60,"elapsed":50357,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["from keras.engine.saving import load_model\n","\n","#validation_size = 1500\n","\n","model = load_model('model.h5')\n","\n","# X_validate = X_test[-validation_size:]\n","# Y_validate = Y_test[-validation_size:]\n","# X_test = X_test[:-validation_size]\n","# Y_test = Y_test[:-validation_size]\n","score,acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n","print(\"score: %.2f\" % (score))\n","print(\"acc: %.2f\" % (acc))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["score: 0.36\n","acc: 0.84\n"],"name":"stdout"}]},{"metadata":{"id":"OqFyLLhfNNuX","colab_type":"code","colab":{}},"cell_type":"code","source":["# print(len(X_validate))\n","# print(len(Y_validate))\n","# print(len(X_test))\n","# print(len(Y_test))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5C0PYZJzNNuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"e6c9afa0-4d27-4b85-aba1-c8d30bae8bfa","executionInfo":{"status":"ok","timestamp":1547386950965,"user_tz":-60,"elapsed":103318,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["twt = ['you will love your kindle2']\n","#vectorizing the tweet by the pre-fitted tokenizer instance\n","twt = tokenizer.texts_to_sequences(twt)\n","#padding the tweet to have exactly the same shape as `embedding_2` input\n","twt = pad_sequences(twt, maxlen=61, dtype='int32', value=0)\n","print(twt)\n","sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n","print(sentiment)\n","if(np.argmax(sentiment) == 1):\n","    print(\"positive\")\n","elif (np.argmax(sentiment) == 0):\n","    print(\"negative\")"],"execution_count":44,"outputs":[{"output_type":"stream","text":["[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  6 36 23 42]]\n","[0.03445405 0.9654247 ]\n","positive\n"],"name":"stdout"}]},{"metadata":{"collapsed":true,"id":"tOAp1PCzNNuc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"286ba9d6-307e-412e-b9a6-3edf9218185e","executionInfo":{"status":"ok","timestamp":1547387495224,"user_tz":-60,"elapsed":152694,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["model = load_model('model.h5')\n","sentiment_predicted = []\n","for tweet in test['text_no_tag']:\n","    tweet = tokenizer.texts_to_sequences(tweet)\n","    #set maxlen as embedding_1 (find it in: embedding_1 (Embedding)      (None, 53, 128)           256000)\n","    tweet = pad_sequences(tweet, maxlen=61, dtype='int32', value=0)\n","    sentiment = model.predict(tweet, batch_size=1, verbose=2)[0]\n","    sentiment_predicted.append(np.argmax(sentiment))\n","\n","print(sentiment_predicted)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"metadata":{"id":"46boWffTNNue","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"a1d7aa2b-b667-413d-e5f9-845d36dc43c5","executionInfo":{"status":"ok","timestamp":1547387533157,"user_tz":-60,"elapsed":1006,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test['polarity_nn'] = sentiment_predicted\n","\n","test.head()"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","      <th>polarity_nn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@USER i love  my kindle2 . not that the  is co...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>reading my kindle2 .  love it .  lee childs is...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ok , first assesment of the kindle 2 .  it fuc...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER you will love your kindle2 . i have had ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@USER fair enough . but i have the kindle2 and...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         text_no_tag  polarity  polarity_nn\n","0  @USER i love  my kindle2 . not that the  is co...         1            0\n","1  reading my kindle2 .  love it .  lee childs is...         1            0\n","2  ok , first assesment of the kindle 2 .  it fuc...         1            0\n","3  @USER you will love your kindle2 . i have had ...         1            0\n","4  @USER fair enough . but i have the kindle2 and...         1            0"]},"metadata":{"tags":[]},"execution_count":51}]},{"metadata":{"id":"a2gH6QDbNNuh","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LNwKzsJENNuj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"1c2d2254-8bc9-4fa9-c9af-fbe44f6b181e","executionInfo":{"status":"ok","timestamp":1547387537243,"user_tz":-60,"elapsed":681,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test.head()"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","      <th>polarity_nn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@USER i love  my kindle2 . not that the  is co...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>reading my kindle2 .  love it .  lee childs is...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ok , first assesment of the kindle 2 .  it fuc...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER you will love your kindle2 . i have had ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@USER fair enough . but i have the kindle2 and...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         text_no_tag  polarity  polarity_nn\n","0  @USER i love  my kindle2 . not that the  is co...         1            0\n","1  reading my kindle2 .  love it .  lee childs is...         1            0\n","2  ok , first assesment of the kindle 2 .  it fuc...         1            0\n","3  @USER you will love your kindle2 . i have had ...         1            0\n","4  @USER fair enough . but i have the kindle2 and...         1            0"]},"metadata":{"tags":[]},"execution_count":53}]},{"metadata":{"id":"-NxhvFK4NNul","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"5c2e85ac-ff9e-42c6-d4f5-3fa9e17cc5b8","executionInfo":{"status":"ok","timestamp":1547387540112,"user_tz":-60,"elapsed":1077,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["print(\"Accuracy sore: \", accuracy_score(test['polarity'], test['polarity_nn']))\n","print(\"Precision score: \", precision_score(test['polarity'], test['polarity_nn'], average='binary'))\n","print(\"Recall score: \", recall_score(test['polarity'], test['polarity_nn'], average='binary'))\n","print(\"F-measure score: \", f1_score(test['polarity'], test['polarity_nn'], average='binary'))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Accuracy sore:  0.5097493036211699\n","Precision score:  0.5208333333333334\n","Recall score:  0.41208791208791207\n","F-measure score:  0.4601226993865031\n"],"name":"stdout"}]},{"metadata":{"id":"2ymwNpOxa1-Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"02210ec3-16ee-4b9e-a7a2-feb1c496b275","executionInfo":{"status":"ok","timestamp":1547387123815,"user_tz":-60,"elapsed":1123,"user":{"displayName":"Daniela Occhipinti","photoUrl":"https://lh4.googleusercontent.com/-ZdxWhjAXYP4/AAAAAAAAAAI/AAAAAAAAAdk/O4toFdO6uy4/s64/photo.jpg","userId":"04139377527506556764"}}},"cell_type":"code","source":["test.tail()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_no_tag</th>\n","      <th>polarity</th>\n","      <th>polarity_nn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>354</th>\n","      <td>after using latex a lot , any other typeset ma...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>355</th>\n","      <td>on that note , i hate word . i hate pages . i ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>ah  .  back in a *real* text editing environme...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>trouble in iran , i see . hmm . iran . iran so...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>reading the tweets coming out of iran .  the w...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           text_no_tag  polarity  polarity_nn\n","354  after using latex a lot , any other typeset ma...         1            0\n","355  on that note , i hate word . i hate pages . i ...         0            0\n","356  ah  .  back in a *real* text editing environme...         1            0\n","357  trouble in iran , i see . hmm . iran . iran so...         0            0\n","358  reading the tweets coming out of iran .  the w...         0            0"]},"metadata":{"tags":[]},"execution_count":49}]}]}